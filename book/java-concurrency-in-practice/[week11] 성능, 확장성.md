# 성능, 확장성
- 스레드를 사용하는 가장 큰 목적은 성능을 높이고자 하는 것
- 스레드를 사용하면 시스템 자원을 효율적으로 활용할 수 있고, 애플리케이션으로 하여금 시스템이 갖고 있는 능력을 최대한 사용하게 할 수 있음
- 성능을 높이는 방법은 대부분 애플리케이션 구조를 복잡하게 만들어야 하는 경우가 많고, 이에 따라 안전성과 활동성에 문제가 생길 가능성도 적지 않음
- 성능 때문에 안전성을 해쳐서는 안됨

</br>

## 11.1 성능에 대해
- 성능을 높인다는 말은 더 적은 자원을 사용하면서 더 많은 일을 하도록 한다는 것
	- 자원 : CPU, 메모리, 네트웍 속도, DB 처리 속도, etc..
- 어떤 작업을 실행할 때 충분하지 못한 특정 자원 때문에 성능이 떨어지는 현상이 나타난다면, 작업의 성능이 해당 자원에 좌우된다고 함
- 여러 개의 스레드를 사용하려 한다면 당일 스레드 사용보다는 성능상의 비용을 지불해야만 함
	- 스레드 간의 작업을 조율하는데 필요한 오버헤드(락 걸기, 신호 보내기, 메모리 동기화 등)
	- 잦은 컨텍스트 스위칭
	- 빈번한 스레드 생성 및 제거
	- 여러 스레드를 효율적으로 스케쥴링 해야하는 것
- 잘못 설계된 병렬 애플리케이션은 순차적으로 작업을 처리하는 프로그램보다 느리게 동작하는 경우도 있음
- 성능을 목표로한 병렬 프로그래밍을 위해서는 두가지 부분을 우선적으로 생각해야 함
	- 프로그램이 확보할 수 있는 모든 자원을 최대한 활용해야 함
	- 남는 자원이 생길 때마다 그 자원을 최대한으로 활용할 수 있도록 해야 함
- 프로그램에서 스레드를 활용하면 작업을 잘게 나눠 시스템에 꽂힌 CPU가 충분히 동작해야할 만큼의 작업을 실행시켜 노는 CPU가 없을 만큼 작업 실행 성능을 높일 수 있음

</br>

### 11.1.1 성능 대 확장성
- 어플이케이션의 성능은 여러 자료로 측정 가능하며, 서비스 시간, 대기 시간, 처리량 등의 수치를 뽑아 얼마나 빠른지 그리고 얼마나 많은 양을 할 수 있는지를 알 수 있음
- 확장성(scalability)은 CPU, 메모리, 디스크, I/O 처리 장치 등의 추가적인 장비를 사용해 처리량이나 용량을 얼마나 쉽게 키울 수 있는지를 말함
- 단일 스레드 환경의 애플리케이션은 별 다른 튜닝을 하지 않아도 3-티어 모델의 애플리케이션 보다 성능이 좋은 경우가 많음
- 그러나, 최대 부하를 넘어서는 경우 단시간에 처리 용량을 증가시킬 수 없으므로 서비스 시간이 훨씬 길어져 하드웨어 자원의 양이 크게 늘어나는 일을 감수해야 함

### 11.1.2 성능 트레이드 오프 측정
- 트레이드 오프에서 어떤 부분을 선택해야 할지를 결정하는데 필요한 정보가 충분하지 않은 경우가 많음
- 최적화 기법을 너무 이른 시점에 적용하지 말아야 함
- 제대로 동작하게 만들고 난 다음에 빠르게 동작하도록 최적화해야 하며, 예상한 것보다 심각하게 성능이 떨어지는 경우에만 최적화 기법을 적용하는 것으로도 충분함
- 성능을 최적화하는 다수의 경우에 코드의 가독성과 유지보수의 용이함을 비용으로 지불함
	- 좀 더 '최적화'되거나 동작하는 모습이 덜 분명한 코드일수록 이해하기가 어렵고 유지보수도 어려움
- 병렬 프로그램에서 발생하는 버그는 추적하고 발견해 수정하기가 어렵지만, 버그의 원이이 될 가능성이 조금이라도 있는 위험도 높은 코드의 경우 매우 주의 깊게 살펴봐야 함
- 성능을 높이기 위해 안전성을 떨어뜨리는 것은 최악의 상황이며, 안전성과 성능 둘 다를 놓칠 수 있음
- 성능을 튜닝하는 모든 과정에서 항상 성능 목표에 대한 명확한 요구 사항이 있어야 하며, 그에 따라 어느 부분을 튜닝하고 어느 시점에서 튜닝을 그만 둬야하는지를 판단할 수 있음
- 특별히 성능을 높이길 원하지 않는다면, 안정성과 유지보수에 대한 비용을 지불해 가면서 성능을 높일 필요는 없음
- 추측하지 말고, 실제로 측정해보라

</br>

## 11.2 암달의 법칙
- 암달의 법칙(Amdahl’s law)을 사용하면 병렬 작업과 순차 작업의 비율에 따라 하드웨어 자원을 추가로 투입했을 때 이론적으로 속도가 얼마나 빨라질지에 대한 예측 값을 얻을 수 있음
- `속도 증가량 <= 1 / ( F + (1-F) / N )`  
	- F : 순차적으로 실행돼야 하는 작업의 비율
	- N : 하드웨어에 꽂혀 있는 프로세서의 개수
- 프로세서인 N 이 무한대면 속도 증가량은 최대 1/F
- 순차적 실행 부분이 전체 50% 라면 프로세서를 아무리 많이 꽂아도 겨우 2배 빨라지는 것
- 암달의 법칙을 이용하면 순차 처리 하는 부분이 많아질때 얼마나 느려지는지 수치화 할 수 있음
- 하드웨어에 CPU 가 10개 꽂혀있으면 10%의 순차작업을 갖고 있는 프로그램은 최고 5.3배 만큼의 속도가 증가 할 수 있음
	- 53%의 CPU 활용도를 가짐 (cpu가 10개이므로 5.3 * 	10 ==> 53)
	- 1 / ( 0.1 + ( 1 – 0.1) / 10) = 5.26...
- 순차적으로 실행해야하는 부분이 조금이라도 늘면 프로세스의 비해 얻을 수 있는 속도 증가량이 크게 떨어짐
![amdahl-ex01](/img/amdahl-ex01.png)      


~~~java
public class WorkerThread extends Thread {
    private final BlockingQueue<Runnable> queue;
    
    public WorkerThread(BlockingQueue<Runnable> queue) {
        this.queue = queue;
    }

    @Override
    public void run() {
        while (true) {
            try {
                Runnable task = queue.take();
                task.run();
            } catch (InterruptedException e) {
                break; /* 스레드를 종료시킨다. */
            }
        }
    }
}
~~~
- 작업 큐에서 작업을 하나씩 뽑는 부분이 순차 처리해야 하는 부분
- 모든 작업 스레드가 작업 큐를 쓸 수 있기 때문에, 적당한 동기화 작업이 선행 되어야 함
- LinkedList 보다는 LinkedBlockingQueue 를 사용하면 대기하는 시간이 훨씬 적게 들지만,어찌됐던 간에 순차적으로 처리해야 하는건 마찬가지
- Runnable 인터페이스는 항상 실행 결과를 로그 파일에 적어두거나, 특정 데이터 구조에 실행 결과를 쌓아두도록 되어 있음
	- 로그 파일이나 결과를 저장하는 기타 데이터 구조 모두 무작위 순서로 만들어내는 결과를 받아들일 수 있어야하기 때문에 순차적으로 처리해야만 하는 부분이라 볼 수 있음
- 모든 병렬 프로그램에는 항상 순차적으로 실행돼야만 하는 부분이 존재함
- 만약 그런 부분이 없다고 생각한다면, 프로그램 코드를 다시 한번 들여다보라

### 11.2.1 예제: 프레임웍 내부에 감춰져 있는 순차적 실행 구조
- 애플리케이션 내부 구조에 순차적으로 처리해야 하는 구조가 어떻게 숨겨져 있는지 알아보려면, 스레드 개수를 증가시킬 때마다 성능이 얼마나 빨라지는지를 기록해두고, 성능상의 차이점을 기반으로 순차적으로 처리하는 부분이 얼만큼인지 추측해 볼 수 있음
![compare-queue](/img/compare-queue.png)     
  
- synchronizedList 메소드로 동기화한 LinkedList 클래스와 ConcurrentLinkedQueue 클래스
	- 스레드 안전성이 보장된 두 가지의 queue 구현 클래스
- 단순히 적절한 큐 구현 클래스를 사용하는 것만으로도 확장성을 크게 높일 수 있음
- 처리량의 차이점이 발생하는 원인은 두 개의 큐 구현 클래스가 작업을 순차적으로 처리하는 정도의 차이점에 원인이 있음
- 동기화된 LinkedList 클래스는 전체 큐의 상태를 하나의 락으로 동기화하고 있어, offer나 remove 메소드를 호출하는 동안 전체 큐가 모두 락에 걸림
- ConcurrentLinkedQueue 클래스는 개별 링크 포인터마다 단일 연산으로 업데이트하는 방법을 사용해 대기 상태에 들어가는 경우를 최소화 함
- 동기화된 LinkedList에서는 추가/삭제 작업이 모두 순차적으로 처리되야 하지만, ConcurrentLinkedQueue 에서는 개별 포인터에 대한 업데이트 연산만 순차적으로 처리하면 됨

### 11.2.2 정성적인 암달의 법칙 적용 방법
- 순차 처리되는 비율을 알지 못해도 암달의 법칙을 사용할 수 있음
- 락의 적용 범위를 줄이는 방법
	- 락 분할(하나의 락을 두개로 분리) 방법과 락 스트라이핑(하나의 락을 여러 개로 분리)
- 암달의 법칙이라는 측면에서, 락을 두개로 분할하는 정도로는 다수의 프로세서를 충분히 활용하기 어려움
- 락 스트라이핑 방법을 사용할 때는 프로세서 수가 늘어남에 따라 분할 개수를 같이 증가시킬 수 있기 때문에 확자성을 얻는데 믿을만한 방법임

</br>

## 11.3 스레드와 비용
- 실행 스케줄링과 스레드 간의 조율을 하다보면 성능에 부정적인 비용이 발생함
- 스레드를 사용하는 경우, 병렬 실행으로 얻을 수 있는 이득이 병렬로 실행하느라 드는 비용을 넘어서야 성능을 향상 시킬 수 있음

</br>

### 11.3.1 컨텍스트 스위칭
- 컨텍스트 스위칭이란 스레드 스케줄링에 의해 다음 스레드가 실행되야 할 때 현재 스레드의 실행 상태를 보관해 두고, 다음 스레드의 실행 상태를 읽어들이는 것을 말함
- 스레드 스케줄링을 하려면 운영체제와 JVM 내부의 공용 자료 구조를 다뤄야 함
- 운영체제와 JVM은 스레드가 사용하는 것과 같은 CPU 를 사용하고 있어, 운영체제나 JVM이 CPU를 많이 사용할수록 스레드가 사용할 CPU가 줄어듦
- 컨텍스트 스위칭에 필요한 부하와 비용은 플랫폼마다 다르지만, 대략 살펴본 바에 따르면 최근 사용되는 프로세서상에서 5,000 ~ 10,000 클럭 사이클 또는 수 마이크로 초 동안의 시간을 소모한다고 알려져 있음
- 유닉스 시스템의 vmstat 명령이나 윈도우 시스템의 perfmon 유틸리티를 사용하면 컨텍스트 스위칭이 일어난 횟수를 확인할 수 있드며 커널 수준에서 얼마만큼의 시간을 소모했는지 확인할 수 있음
- 커널 활용도가 10%가 넘는 높은 값을 갖고 있다면 스케줄링에 부하가 걸린다는 의미이며, 애플리케이션 내부에서 I/O 작업이나 락 관련 동기화 부분에서 대기 상태에 들어가는 부분이 원인일 가능성이 높음

### 11.3.2 메모리 동기화
- synchronized , voliatile 키워드를 사용하면 가시성을 통해 메모리 배리어(barrier) 명령어를 사용할 수 있음
- 메모리 배리어는 캐시를 플러시하거나 무효화하고, 하드웨어와 관련된 쓰기 버퍼를 플러시하고, 실행 파이프라인을 늦출 수도 있음
- 메모리 배리어를 사용하면 컴파일러가 제공하는 여러가지 최적화 기법을 제대로 사용할 수 없어 간접적인 성능 문제를 가져올 수 있음
	- 명령어 재배치를 배부분 할 수 없게 되기 때문
- 동기화가 성능에 미치는 영향을 파악하려면 동기화 작업이 경쟁적인지, 비경쟁적인지 확인해야 함
- synchronized 키워드는 비경쟁적인 경우에 최적화 되어있고 비경쟁적이면서 동기화 방법은 성능에 큰 영향은 없음
	- volatile은 항상 비경쟁적임
- 최근에 사용하는 JVM은 대부분 다른 스레드와 경쟁할 가능성이 없다고 판단되는 부분에 락이 걸려 있다면 최적화 과정에서 해당 락을 사용하지 않도록 방지하는 기능을 제공하기도 함
~~~java
public String getStoogeNames() {
        List<String> stooges = new Vector<String>();
        stooges.add("Moe");
        stooges.add("Larry");
        stooges.add("Curly");
        return stooges.toString();
    }
~~~
- 정교하게 만들어진 JVM의 경우에는 유출 분석(escape analysis)을 통해 로컬 변수가 외부로 공개된 적이 있는지 없는지, 해당 변수가 스레드 내부에서만 사용되는지를 판단하기도 함
- 허술한 JVM 은 Vector 에 add 하는 부분과 toString 을 사용하는 곳에서 총 4번 락을 잡았다 놓았다 하지만 정교한 JVM 에서는 외부에 유출이 되지 않고 메소드 내부에서만 실행되는걸 확인하고 락을 잡지 않고 빠르게 실행시킴
- 유출분석을 하지 않는 경우라면, 연달아 있는 락은 하나의 락으로 묶는 락 확장 기능을 사용하기도 함
- 락 확장 방법을 사용하면 동기화 관련 부하를 줄이는 데 도움을 줄 뿐만 아니라 최적화 모듈이 좀 더 큰 단위의 블록을 대상으로 추가적인 최적화 작업을 진행할 기회가 생기기도 함
- 경쟁 조건에 들어가지 않는 동기화 블록에 대해서는 걱정하지 않아도 됨
- 동기화 블록의 기본적인 구조가 상당히 빠르게 동작할 뿐만 아니라 JVM 수준에서 동기화와 관련한 추가적인 최적화 작업을 진행하기 때문에 동기화 관련 부하를 줄이거나 아예 없애주기도 함
- 경쟁 조건이 발생하는 동기화 블록을 어떻게 최적화할지에 대해서 고민해야 함
- 특정 스레드가 동기화 작업을 진행하느라 공유 메모리로 통하는 버스의 대역폭을 꽉 잡고 있다면, 동기화 작업을 진행해야 할 다른 스레드는 성능이 떨어질 수 밖에 없음

### 11.3.3 블로킹
- 비경쟁 조건 동기화 작업은 JVM 내부에서 처리할 수 있지만, 경쟁 조건 동기화 작업은 운영체제가 관여해야하며 운영체제가 관여하는 부분은 모두 일정량의 자원을 소모함
- 락을 놓고 경쟁하고 있다면, 락을 확보하지 못한 스레드는 항상 대기 상태에 들어가야 함
- JVM은 스레드를 대기 상태에 둘 때 두가지 방법을 사용할 수 있음
	- 스핀 대기(spin waiting) : 락을 확보할 때까지 계쏙해서 재시도하는 방법
	- 운영체제가 제공하는 기능을 사용해 스레드를 실제 대기 상태로 두는 방법
	- 대기 시간을 놓고 보면, 대기 시간이 짧은 경우에는 스핀 대기 방법이 효과적
	- 대기 시간이 긴 경우에는 운영체제의 기능을 호출하는 편이 효율적이라고 봄
	- 대부분의 경우에는 운영체제의 기능을 호출하는 방법을 사용함

</br>

## 11.4 락 경쟁 줄이기
- 작업을 순차적으로 처리하면 확장성을 놓치고, 작업을 병렬로 처리하면 컨텍스트 스위칭에서 성능에 악영향을 줌
- 락을 놓고 경쟁하는 상황이 벌어지면 순차적으로 처리함과 동기에 컨텍스트 스위칭도 많이 일어나므로 확장성과 성능을 동시에 떨어뜨리는 원인이 됨
- 락으로 사용 제한이 걸려 있는 독점적인 자원을 사용하려는 모든 스레드는 해당 자원을 한 번에 하나의 스레드만 사용할 수 있기 때문에 순차적으로 처리될 수 밖에 없음
- 병렬 애플리케이션에서 확장성에 가장 큰 위협이 되는 존재는 바로 특정 자원을 독점적으로 사용하도록 제한하는 락
- 락을 두고 발생하는 경쟁 상황에는 크게 두가지 원인이 있음
	- 락을 얼마나 빈번하게 확보하려고 하는지
	- 한번 확보하고 나면 해제할 때까지 얼마나 오래 사용하지는지
- 락 경쟁 조건을 줄일 수 있는 방법
	- 락을 확보한 채로 유지되는 시간을 최대한 줄임
	- 락을 확보하고자 요청하는 횟수를 최대한 줄임
	- 독점적인 락 대신 병렬성을 크게 높여주는 여러 가지 조율 방법을 사용

</br>

### 11.4.1 락 구역 좁히기
- 락 경쟁이 발생할 가능성을 줄이는 효과적인 방법은 락을 유지하는 시간을 줄이는 방법
- 락이 꼭 필요하지 않은 코드를 synchronized 블록 밖으로 뽑아내어 락이 영향을 미치는 구역을 좁히면 락 유지시간을 줄일 수 있음
~~~java
@ThreadSafe
public class AttributeStore {
    @GuardedBy("this") private final Map<String, String> attribute = new HashMap<String, String>();
    
    public synchronized boolean userLocationMatches(String name, String regexp) {
        String key = "users." + name + ".location";
        String location = attribute.get(key); 
        if(location == null) 
            return false;
        else
        	return Pattern.matches(regexp, location);
    }
}
~~~
- Map.get() 호출하는 부분만 synchronized로 막아야 함
- AttributeStore 클래스는 필요 이상으로 락을 확보하고 있음

~~~java
@ThreadSafe
public class BetterAttributeStore {
    @GuardedBy("this") private final Map<String, String> attribute = new HashMap<String, String>();

    public boolean userLocationMatches(String name, String regexp) {
        String key = "users." + name + ".location";
        String location;
        synchronized (this) {
            location = attribute.get(key);
        }
        if(location == null)
            return false;
        else
        	return Pattern.matches(regexp, location);
    }
}
~~~
- 필요한 부분에만 synchronized 처리를 하여 락 점유 시간을 줄임
- 암달의 법칙을 통해 보면 순차적으로 처리 돼야 하는 코드의 양이 줄어들어 확장성을 저해하는 요소를 줄이는 결과도 기대할 수 있음
- synchronized 블록을 줄이면 줄일수록 확정성을 늘일 수 있다고 하지만, 단일 연산으로 실행되어야 할 명령어까지 synchronized 블록 밖으로 빼내면 안됨
- synchronized 블록에서 동기화를 맞추는 데도 자원이 필요하기 때문에 하나의 synchronized 블록을 두개 이상으로 쪼개는 일도 어느 한도를 넘어서면 성능의 측면에서 악영향을 미칠 수 있음

### 11.4.2 락 정밀도 높이기
- 
